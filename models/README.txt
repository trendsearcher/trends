названия скриптов отражают их содержание относительно вот этой истории изменений:



К нашей задаче было 2 подхода: использовать картинки в '1d' CNN и цифры, характеризующие картинки. Есть также 2 варианта выставления оценок. 
Пока применяем топорную классификацию up/down для простоты. Классы почти идеально 50/50.. Когда уткнемся в потолок, тогда введем 3й класс и 
попробуем выехать на той же архитектуре. 

На практике оказалось, что цифры работают в лог регрессии, лесах и dnn на игрушечных сетах в 1000 примеров (average acc на кроссвалидации 54%) 
на 2 разных наборах данных.

СNN на картинках (average acc на кроссвалидации 54%) на 2 разных наборах данных. 



Проверим, не идиоты ли мы?



Возможно, есть баг? сгенерируем белый шум и сделаем броуновское движение на псевдослучайных цифрах. И прогоним эти данные через все этапы.
Нет. Мы молодцы. проверка дает ровно 50%.
Теперь проверим, не делаем ли мы лишнюю предподготовку? Может можно обойтись рандомными картинками и так все будет работать. Для проверки 
целесообразности именно такого нашего подхода к задаче попробовал убрать хвост паттерна длиной в 1/2 и во втором случае нарастил паттерн на 1/2. 
В обоих случаях метрики падают в 2-3 раза где-то. Поварьировал разрешение картинок на вход в СNN [500, 1000, 1500] сегментов в длину - 1000 - 
лучше так и оставим.
Интересно, что точность моделек почти идеально совпадала на игрушечных датасатех Логично было проверить, совпадают ли угадываемые моделью
примеры? Совпадают они лишь на 80+-%
Поэтому решил объединить входы моделей в 1 сетку и проверить, есть ли эффект синергии? - не вышло. те же (average acc на кроссвалидации 54%)
Ладно. тогда попробуем дать равные голоса для dnn и cnn и сделать ансамбль. Получили 55% на 3 разных наборах данных.
В дальнейшем будем использовать этот ансамбль, пока ничего лучше не придумано.
 

Интересно, что на 15000 (4года истории) DNN на цифрах почти не работает (если паттерны имеют стационарные характеристики, то странно, надо 
проверить это при последовательном кормлении модели слева направо).
А вот CNN на картинках дает все те же 54%.
Ансамбль - 54%

Есть стойкое ощущение, что мусора у нас много. Ввел 3-й класс для него (метод разметки обговаривали много раз - писать тут не буду) Вроде работает, 
картинки можно зачекать в ноутбуке. АУКи классные по 0.8 на каждый класс. Вроде надо радоваться, но я уже параноик и поэтому проверил результат на 
все том же броуновском движении. И получился какой-то бред. на белом шуме оно там чему-то обучается и даже дает неплохие ауки на Сбере, 
обучившись на шуме. Не могу найти баг, либо логическую ошибку. Меня этот выводит из себя.


===============================================================================================================================================
                                                   попытка отделить предсказываемые примеры от шумовых
===============================================================================================================================================
Это параллельная ветка развития. Придумал подход. Получал хороший результат (60/40)

Первый подход к проблеме.

Делаем 2 набора данных: A и B, которые никак друг с другом не связаны и не имеют ничего общего. Для каждого из них проводим следующие манипуляции: много раз случайным образом отбираем трейн и тест из каждого набора данных. На каждой генерации трейна и теста запускаем обучение на CNN. Предварительно мы знаем, что при заданной скорости обучения и фиксированной мощности выборки и модели получаем пик
максимальных AUC и точности предсказания на тесте. Соответственно при данных настройках на эпоке пика снимаем ошибки, которая
совершает модель на всех примерах (модель не переобучена, что важно). Если при этой эпохе показатели на тестовом множестве выше 
пороговых, то снимаем ошибки модели и отбираем, скажем, 10-20% примеров, где модель наиболее сильно ошиблась. После многократного
запуска на разных случайных выборках получаем распределение очков мусорности. Если они распределены по Гауссу, то мы сделали ерунду. QQ плот ненормальный, есть тяжелые хвосты. Бинаризуем оценки мусорности на различных порогах оценки и проверим, предсказывает ли найронка, обученная на A, примеры из B.

Резюме: не работает. видимо я где-то упустил баг в прошлый раз

===============================================================================================================================================
                                                  проверим влияние ширины окна в будущее на метрики модели
                                                  и проверим то как влияет смещение по времени точек предсказания
                                                  на метрики 
 ===============================================================================================================================================
 
 Очень интересно получается. 
